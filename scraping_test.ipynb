{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://myanimelist.net/users.php\")\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recentOnlineUsers = soup.find_all(class_='picSurround')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recentSlugs = [x.find('a').get('href') for x in recentOnlineUsers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan:\n",
    "\n",
    "- For each user, find all their anime (status=7), rating for each. \n",
    "- Keep track of users, and user's watched anime in database\n",
    "- Also keep track of unique animes, average score, popularity, etc.\n",
    "\n",
    "## TODO:\n",
    "\n",
    "think of how to design database\n",
    "\n",
    "## Data to get from each user:\n",
    "\n",
    "- Anime stats\n",
    "    - \"Days\"\n",
    "    - Mean score\n",
    "    - Num watching\n",
    "    - Num completed\n",
    "    - Plan to watch\n",
    "    - List watching\n",
    "    - List completed\n",
    "    - List Plan to watch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for profile in recentSlugs:\n",
    "    profileResp = requests.get(\"https://myanimelist.net\" + profile)\n",
    "    profileSoup = BeautifulSoup(profileResp.text, 'html.parser')\n",
    "    \n",
    "    # Completed, etc append\n",
    "    # \"?status=n\" where n = 1,2,3,4,5,6\n",
    "    \n",
    "    # class for stats looks like clearfix mb12 inside div with class stats anime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://myanimelist.net/animelist/Hattsworth?status=1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile = recentSlugs[2]\n",
    "profileResp = requests.get(\"https://myanimelist.net\" + profile)\n",
    "profileSoup = BeautifulSoup(profileResp.text, 'html.parser')\n",
    "\n",
    "statsAnime = profileSoup.find(class_ = \"stats anime\")\n",
    "clearfixmb12 = statsAnime.find_all(class_=\"clearfix mb12\")\n",
    "len(clearfixmb12)\n",
    "clearfixmb12\n",
    "\n",
    "# watching, completed, on hold, dropped, plan to watch\n",
    "# hopefully, in that order.\n",
    "\n",
    "clearfixmb12[0].find('a').text # 'watching'\n",
    "clearfixmb12[0].find('span').text # '6'\n",
    "\n",
    "statScore = statsAnime.find(class_=\"stat-score\")\n",
    "statScore = [x for x in list(statScore.children) if x != '\\n'] # get two subdivs, without newlines\n",
    "statScore[0].find('span').text # 'Days: '\n",
    "statScore[0].text.split(': ') # ['Days', '213.4']\n",
    "statScore[1].text.split(': ') # ['Mena Score', '6.92']\n",
    "\n",
    "\n",
    "# list of watching:\n",
    "clearfixmb12[0].find('a').get('href')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a list of watching, completed, etc anime is a bit trickier because the site is an infinite scrolling type. It loads at first 300 results, but you have to scroll to get more. \n",
    "\n",
    "https://myanimelist.net/animelist/Catalano?status=7\n",
    "\n",
    "This will be a case study because they've watched a lot of anime.\n",
    "\n",
    "The simple, but slow approach is to use Selenium to drive an actual browser to scroll and load the data. When it's all done, use BeautifulSoup to read everything. \n",
    "\n",
    "However, I don't want to use Selenium in this project, because I think it's a bit bulky. Since I am only scraping from one site, I figure I can do a bit of hardcoding. Theoretically, the data has to come from somewhere. \n",
    "\n",
    "https://blog.michaelyin.info/how-crawl-infinite-scrolling-pages-using-python/\n",
    "\n",
    "Is a great post on finding the request URL the site makes to the backend to retrieve the data.\n",
    "\n",
    "It looks like the response URL is https://myanimelist.net/animelist/Catalano/load.json?offset=300&status=7 for after the first 300. \n",
    "\n",
    "Going to use Python to dig deeper on how the JSON is structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 2,\n",
       " 'score': 7,\n",
       " 'tags': '',\n",
       " 'is_rewatching': 0,\n",
       " 'num_watched_episodes': 1,\n",
       " 'anime_title': 'Gatchaman Crowds Insight: Inbound',\n",
       " 'anime_num_episodes': 1,\n",
       " 'anime_airing_status': 2,\n",
       " 'anime_id': 30925,\n",
       " 'anime_studios': None,\n",
       " 'anime_licensors': None,\n",
       " 'anime_season': None,\n",
       " 'has_episode_video': False,\n",
       " 'has_promotion_video': False,\n",
       " 'has_video': False,\n",
       " 'video_url': '/anime/30925/Gatchaman_Crowds_Insight__Inbound/video',\n",
       " 'anime_url': '/anime/30925/Gatchaman_Crowds_Insight__Inbound',\n",
       " 'anime_image_path': 'https://myanimelist.cdn-dena.com/r/96x136/images/anime/2/74427.jpg?s=31f643601049374df4ee968b99f0c2d9',\n",
       " 'is_added_to_list': False,\n",
       " 'anime_media_type_string': 'ONA',\n",
       " 'anime_mpaa_rating_string': 'PG-13',\n",
       " 'start_date_string': None,\n",
       " 'finish_date_string': None,\n",
       " 'anime_start_date_string': '20-06-15',\n",
       " 'anime_end_date_string': '20-06-15',\n",
       " 'days_string': None,\n",
       " 'storage_string': '',\n",
       " 'priority_string': 'Low'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "offset0 = requests.get('https://myanimelist.net/animelist/Catalano/load.json?offset=0&status=7')\n",
    "json.loads(offset0.text)[0]\n",
    "\n",
    "offset300 = requests.get('https://myanimelist.net/animelist/Catalano/load.json?offset=300&status=7')\n",
    "json.loads(offset300.text)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`status: 2` probably refers to it being marked \"completed\". `status: 1` probably refers to it being marked \"currently watching\"\n",
    "\n",
    "It looks like if we set `offset=0` then we get the 1-300 (inclusive) anime watched. If we set `offset=300` then we get the 301-600 animes watched. What happens if the offset is more than they've watched?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset3000 = requests.get('https://myanimelist.net/animelist/Catalano/load.json?offset=3000&status=7')\n",
    "json.loads(offset3000.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "animeSoup = BeautifulSoup(requests.get('https://myanimelist.net/anime/31646/').text, 'html.parser')\n",
    "\n",
    "# what anime information do we want?\n",
    "# Score\n",
    "# Genres\n",
    "\n",
    "# getting genres\n",
    "\n",
    "testlist = [x for x in animeSoup.find_all(class_=\"dark_text\") if 'Genres' in x.text]\n",
    "pardiv = testlist[0].parent\n",
    "listOfGenres = [x.text for x in pardiv.find_all('a')]\n",
    "\n",
    "# getting Score\n",
    "score = animeSoup.find(itemprop=\"ratingValue\").text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"spaceit po-r js-statistics-info di-ib\" data-id=\"info2\">\n",
       "<span class=\"dark_text\">Ranked:</span>\n",
       "  #144<sup>2</sup>\n",
       "<div class=\"statistics-info info2\">\n",
       "<small><sup>2</sup>\n",
       "    based on the <a href=\"/topanime.php\">top anime</a> page. Please note that 'Not yet aired' and 'R18+' titles are excluded.\n",
       "    </small>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorediv = [x.parent for x in animeSoup.find_all(class_=\"dark_text\") if 'Ranked' in x.text][0]\n",
    "scorediv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-03fdf0154211>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manimeSoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ratingValue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'int'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an empty list when we try to ask for more than they've watched. I think a simple try/catch block on a list index out of range should handle the error well enough. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I have a good way to get all the data I need, all that's left is to store it. Since the plan is to run a script periodically, I want my data to persist, so I'll try using a database. \n",
    "\n",
    "I'm also new to database, so this is also a first attempt at databases.\n",
    "\n",
    "What I want to store is many users and many anime that have a many to many relationship, in that users watch many anime and an anime is watched by many users. It took some time to manage to formulate this idea with this language, but once I did, I found that I need to use a junction table (in a relational database world) to achieve this sort of relationship. The lack of \"tuples\" or \"lists\" in SQL was really messing with my brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = recentSlugs[1]\n",
    "\n",
    "#def writeToDB(profileurl):\n",
    "# Days\n",
    "# Mean Score\n",
    "# Watch list\n",
    "# Completed list\n",
    "# Plan to watch list\n",
    "\n",
    "profileResp = requests.get(\"https://myanimelist.net\" + profile)\n",
    "profileSoup = BeautifulSoup(profileResp.text, 'html.parser')\n",
    "\n",
    "username = profile.split('/')[-1]\n",
    "\n",
    "# if username already here, just stop TODO\n",
    "\n",
    "# Get days and mean score\n",
    "statsAnime = profileSoup.find(class_ = \"stats anime\")\n",
    "statScore = statsAnime.find(class_=\"stat-score\")\n",
    "statScore = [x for x in list(statScore.children) if x != '\\n'] # get two subdivs, without newlines\n",
    "statScore[0].find('span').text # 'Days: '\n",
    "\n",
    "numdays = int(float(statScore[0].text.split(': ')[1])) # ['Days', '213.4']\n",
    "meanscore = int(float(statScore[1].text.split(': ')[1])) # ['Mea Score', '6.92']\n",
    "\n",
    "# add it to SQL table\n",
    "\n",
    "conn = sqlite3.connect('testdb.db')\n",
    "c = conn.cursor()\n",
    "c.execute('insert into users values ( \"{un}\", {nd}, {ms} );'\\\n",
    "         .format(un=username, nd=numdays, ms=meanscore))\n",
    "conn.close()\n",
    "\n",
    "\n",
    "# Get Animes\n",
    "# Do a while loop, until fail to pull. This is the end.\n",
    "\n",
    "# animelist string:\n",
    "animelistURL = 'https://myanimelist.net/animelist/' + username\n",
    "currpage = 0\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get big animelist\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        listRequest = requests.get(animelistURL + 'load.json?offset=' + currPage + '&status=7')\n",
    "        animelist = json.loads(listRequest.text)\n",
    "        \n",
    "        for anime in animelist:\n",
    "            # Add to junction table and anime table\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "import time # prevent server from denying requests\n",
    "username = 'Catalano'\n",
    "animelistURL = 'https://myanimelist.net/animelist/' + username\n",
    "currPage = 0\n",
    "runninglist = []\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        listRequest = requests.get(animelistURL + '/load.json?offset=' + str(currPage*300) + '&status=7')\n",
    "        animelist = json.loads(listRequest.text)\n",
    "        if animelist == []:\n",
    "            break\n",
    "        runninglist += [x['anime_title'] for x in animelist]\n",
    "        currPage += 1\n",
    "        time.sleep(1)\n",
    "except ValueError:\n",
    "    print(\"error: below is request text:\")\n",
    "    print(listRequest.text)\n",
    "    print(listRequest)\n",
    "\n",
    "print(\"success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1104"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(runninglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # prevent server from denying requests\n",
    "username = 'Catalano'\n",
    "animelistURL = 'https://myanimelist.net/animelist/' + username\n",
    "currPage = 0\n",
    "runninglist = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "listRequest = requests.get(animelistURL + '/load.json?offset=' + str(currPage*300) + '&status=7')\n",
    "animelist = json.loads(listRequest.text)\n",
    "runninglist = runninglist + tuple(x['anime_title'] for x in animelist)\n",
    "currPage += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1104"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(runninglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[]'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listRequest.textthu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('testdb.db')\n",
    "c = conn.cursor()\n",
    "c.execute('insert into users values ( \"{un}\", {nd}, {ms} );'\\\n",
    "         .format(un=username, nd=numdays, ms=meanscore))\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('MangaReader225', 56, 6)]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('testdb.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute(\"select * from users;\")\n",
    "print(c.fetchall())\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animelist[0]['score']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
